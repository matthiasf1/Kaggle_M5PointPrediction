{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ggf. zu float16 konvertieren checken, ob finaler df mit time slices dann deutlich kleiner und performance testen\n",
    "- Cross validation?\n",
    "- Ensemble learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data handling libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify directories\n",
    "#code_env = 'kaggle'\n",
    "code_env = 'local'\n",
    "\n",
    "\n",
    "if code_env=='local':\n",
    "    ###local###\n",
    "    #get parent folder of current directory\n",
    "    parent_dir = '/Users/mf/Desktop/CS/Studies/7_Final_Project/Kaggle_M5PointPrediction'\n",
    "\n",
    "    #Directory resources\n",
    "    res_dir = parent_dir + '/res/'\n",
    "    src_dir = parent_dir + '/src/'\n",
    "    prc_dir = src_dir + 'processed_data/' # Processed data directory with pickled dataframes\n",
    "\n",
    "if code_env=='kaggle':\n",
    "    ###On Kaggle###\n",
    "    res_dir = '/kaggle/input/m5-forecasting-accuracy/'\n",
    "    prc_dir = '/kaggle/input/processed-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables\n",
    "BASE     = prc_dir +'df_1.pkl'\n",
    "CALENDAR = prc_dir +'df_2.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in df_train_conv from pickle file\n",
    "df_all_data = pd.concat([pd.read_pickle(BASE),\n",
    "           pd.read_pickle(CALENDAR)], \n",
    "           axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "TRAIN_END = 1913 - 28 # 1885 -> Train only until the 28 days before the end of the data\n",
    "VAL_END = 1913\n",
    "\n",
    "df_train = df_all_data[df_all_data['d'] <= TRAIN_END]\n",
    "#df_val = df_all_data[(df_all_data['d'] > TRAIN_END) & (df_all_data['d'] <= VAL_END)]\n",
    "#df_test = df_all_data[df_all_data['d'] > VAL_END]\n",
    "\n",
    "del df_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical columns\n",
    "categorical_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'wday', \n",
    "                    'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', \n",
    "                    'snap_CA', 'snap_TX', 'snap_WI', 'mday', 'week', 'month', 'year']\n",
    "numerical_cols = ['sell_price']\n",
    "\n",
    "target_col = 'sales_amount'\n",
    "\n",
    "# Convert categorical columns to category dtype and encode with cat.codes\n",
    "for col in categorical_cols:\n",
    "    df_train[col] = df_train[col].astype('category').cat.codes\n",
    "\n",
    "# Normalize numerical columns\n",
    "scaler = MinMaxScaler()\n",
    "df_train[numerical_cols] = scaler.fit_transform(df_train[numerical_cols].astype(np.float32))\n",
    "df_train['sales_amount'] = scaler.fit_transform(df_train[['sales_amount']].astype(np.float32))\n",
    "\n",
    "\n",
    "# LSTM Data Preparation\n",
    "time_steps = 7  # Number of time steps (can be tuned)\n",
    "batch_size = 32  # Batch size for the generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom RMSE loss function\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Generator Function\n",
    "def lstm_data_generator(df, target, days_per_sequence=1, batch_size=32):\n",
    "    num_items = df[df['d'] == 1].shape[0]  # 30490 -> Number of items per day\n",
    "    total_sequences = (len(df) - num_items * days_per_sequence) // num_items # 1878\n",
    "    while True:  # Loop indefinitely, the model's fit method will break the loop\n",
    "        for i in range(0, total_sequences, batch_size):\n",
    "            batch_sequences = []\n",
    "            batch_targets = []\n",
    "            for b in range(batch_size):\n",
    "                if i + b < total_sequences: # 0, 0; 0, 1; 0, 2; ...; 0, 32; 32, 0; 32, 1; ...\n",
    "                    start_idx = (i + b) * num_items\n",
    "                    end_idx = start_idx + num_items * days_per_sequence\n",
    "                    batch_sequences.append(df.iloc[start_idx:end_idx, :].drop(target, axis=1).to_numpy()) #drop target column, Only the values in the DataFrame will be returned, the axes labels will be removed.\n",
    "                    batch_targets.append(df.iloc[end_idx:end_idx + num_items][target].to_numpy())\n",
    "            yield np.array(batch_sequences), np.array(batch_targets)\n",
    "\n",
    "# Usage\n",
    "time_steps = 7  # Number of days per sequence\n",
    "batch_size = 32  # Size of each batch\n",
    "train_gen = lstm_data_generator(df_train, target_col, days_per_sequence=time_steps, batch_size=batch_size)\n",
    "num_items = df_train[df_train['d'] == 1].shape[0]  # Number of items per day (day 1 examplary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_gen.__next__()[1].shape  # (32, 30490, 16) -> (batch_size, num_items, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM Model\n",
    "input_shape = (time_steps * num_items, len(df_train.columns) - 1)  # Adjust input shape accordingly\n",
    "model_input = Input(shape=input_shape)\n",
    "x = LSTM(50, activation='relu')(model_input)\n",
    "x = Dense(1)(x)\n",
    "model = Model(inputs=model_input, outputs=x)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 09:12:23.766743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-01-09 09:12:23.788249: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/58 [==>...........................] - ETA: 32:15 - loss: nan"
     ]
    }
   ],
   "source": [
    "# Train the model using the generator\n",
    "model.fit(train_gen, steps_per_epoch=(len(df_train) // (batch_size * num_items)), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_sequences(df, target, days_per_sequence=1):    \n",
    "#     num_items = df_train[df_train['d'] == 1].shape[0]  # Number of items per day (day 1 examplary)\n",
    "#     X, y = [], []\n",
    "\n",
    "#     for i in range(0, len(df) - num_items * days_per_sequence, num_items):\n",
    "#         end_idx = i + num_items * days_per_sequence\n",
    "#         X.append(df.iloc[i:end_idx, :].drop(target, axis=1).values)\n",
    "#         y.append(df.iloc[end_idx:end_idx + num_items][target].values)\n",
    "\n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "# # Usage\n",
    "# time_steps = 7  # Number of days per sequence\n",
    "# X_train, y_train = create_sequences(df_train, target_col, days_per_sequence=time_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After prediction\n",
    "# predictions_normalized = model.predict(...)  # Predictions in the normalized scale\n",
    "# predictions_original = scaler.inverse_transform(predictions_normalized)  # Inverse-transformed predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_bsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
