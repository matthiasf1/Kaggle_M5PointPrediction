{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:28:45.714019Z","iopub.status.busy":"2024-02-04T10:28:45.713557Z","iopub.status.idle":"2024-02-04T10:28:45.724837Z","shell.execute_reply":"2024-02-04T10:28:45.723860Z","shell.execute_reply.started":"2024-02-04T10:28:45.713975Z"},"trusted":true},"outputs":[],"source":["# Setting to adjust before each run:\n","MODEL_NAME = 'V3_ohne_Cat_features_block_items'\n","CODE_ENV = 'local' #'kaggle', 'aws', 'local'\n","STATUS = 'production' #'training'"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:28:45.726757Z","iopub.status.busy":"2024-02-04T10:28:45.726461Z","iopub.status.idle":"2024-02-04T10:28:49.601403Z","shell.execute_reply":"2024-02-04T10:28:49.600379Z","shell.execute_reply.started":"2024-02-04T10:28:45.726733Z"},"trusted":true},"outputs":[],"source":["#Import data handling libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import Input, LSTM, Dense, Masking, RepeatVector, Dropout, Reshape\n","from keras.optimizers import Adam\n","from keras.metrics import RootMeanSquaredError\n","from keras import backend as K\n","from keras.callbacks import Callback\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:28:49.603096Z","iopub.status.busy":"2024-02-04T10:28:49.602532Z","iopub.status.idle":"2024-02-04T10:28:49.707155Z","shell.execute_reply":"2024-02-04T10:28:49.706050Z","shell.execute_reply.started":"2024-02-04T10:28:49.603066Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Num GPUs Available:  0\n","False\n"]}],"source":["# Check if GPU is available\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","print(tf.test.is_built_with_cuda())"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:28:49.710168Z","iopub.status.busy":"2024-02-04T10:28:49.709769Z","iopub.status.idle":"2024-02-04T10:28:49.717151Z","shell.execute_reply":"2024-02-04T10:28:49.716162Z","shell.execute_reply.started":"2024-02-04T10:28:49.710139Z"},"trusted":true},"outputs":[],"source":["#Specify directories\n","if CODE_ENV=='local':\n","    ###local###\n","    #get parent folder of current directory\n","    parent_dir = '/Users/mf/Desktop/CS/Studies/7_Final_Project/Kaggle_M5PointPrediction'\n","\n","    #Directory resources\n","    res_dir = parent_dir + '/res/'\n","    src_dir = parent_dir + '/src/'\n","    prc_dir = src_dir + 'processed_data/' # Processed data directory with pickled dataframes\n","    sub_dir = src_dir + 'submissions/' # Directory to save submission files\n","\n","if CODE_ENV=='kaggle':\n","    ###On Kaggle###\n","    res_dir = '/kaggle/input/m5-forecasting-accuracy/'\n","    prc_dir = '/kaggle/input/processed-data-v3/'\n","\n","if CODE_ENV=='aws':\n","    parent_dir = '/home/ubuntu/projects/Kaggle_M5PointPrediction'\n","    res_dir = parent_dir + '/res/'\n","    src_dir = parent_dir + '/src/'\n","    prc_dir = src_dir + 'processed_data/' # Processed data directory with pickled dataframes\n","    sub_dir = src_dir + 'submissions/' # Directory to save submission files"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:28:49.718565Z","iopub.status.busy":"2024-02-04T10:28:49.718293Z","iopub.status.idle":"2024-02-04T10:28:49.727911Z","shell.execute_reply":"2024-02-04T10:28:49.727014Z","shell.execute_reply.started":"2024-02-04T10:28:49.718540Z"},"trusted":true},"outputs":[],"source":["# Create variables\n","VALIDATION_DATA  = prc_dir +'df_1.pkl' # Validation data\n","BASE      = prc_dir +'df_2.pkl' # Base data\n","CALENDAR  = prc_dir +'df_3.pkl' # Calendar data\n","NUM_ITEMS = 30490 # Number of items per each day\n","DAYS_PER_SEQUENCE = 14  # Length of the sequence\n","TARGET_COL = 'sales_amount'\n","# REPEATED_FEATURES = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'sales_amount', 'sell_price', 'is_available'] # List to hold all feature columns that are used for each item\n","REPEATED_FEATURES = ['sell_price', 'is_available'] # List to hold all feature columns that are used for each item\n","# ONCE_ONLY_FEATURES = ['d', 'wday', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'mday', 'week', 'month', 'year', 'snap_CA', 'snap_TX', 'snap_WI'] # List to hold feature columns that are not repeated for each item\n","ONCE_ONLY_FEATURES = ['snap_CA', 'snap_TX', 'snap_WI', 'mday_normalized', 'month_sin', 'month_cos', 'wday_sin', 'wday_cos', 'week_sin', 'week_cos', 'year_normalized'] # List to hold feature columns that are not repeated for each item"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Set test_end to 1969 in case of production\n","if STATUS=='production':\n","    TEST_END = 1969\n","elif STATUS=='training':\n","    TEST_END = 1941\n","\n","# Splitting the data in train, validation and test set; days are now 0 based, so have to shift by 1\n","# Define duration in days of each set\n","VAL_DUR   = 28\n","TEST_DUR  = 28\n","\n","# Define end days of training set for each set\n","VAL_END   = TEST_END - TEST_DUR\n","TRAIN_END = VAL_END - VAL_DUR # 1885 -> Train only until the 28 days before the end of the data\n","\n","# Finally define duration in days for the train set\n","TRAIN_DUR = TRAIN_END - DAYS_PER_SEQUENCE# Depends on whether the whole dataset is used or last the 28 days for validation "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:28:49.729350Z","iopub.status.busy":"2024-02-04T10:28:49.728998Z","iopub.status.idle":"2024-02-04T10:28:53.163392Z","shell.execute_reply":"2024-02-04T10:28:53.162542Z","shell.execute_reply.started":"2024-02-04T10:28:49.729323Z"},"trusted":true},"outputs":[],"source":["# Read in df_train_conv from pickle file\n","def get_whole_data():\n","    df_all_data = pd.concat([pd.read_pickle(BASE),\n","           pd.read_pickle(CALENDAR)], \n","           axis=1)\n","    return df_all_data"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Return a df with all unique combinations of store_id and dept_id\n","def get_combinations(df_all_data):\n","    # get all store_id and dept_id combinations\n","    df_combinations_store_dep = df_all_data[['store_id','dept_id']].drop_duplicates().reset_index(drop=True)\n","\n","    return df_combinations_store_dep"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Filter df down to only the current store_id and dept_id combination\n","def filter_df(df_combinations_store_dep, df_all_data, i):\n","    store_id = df_combinations_store_dep.loc[i, 'store_id']\n","    dept_id = df_combinations_store_dep.loc[i, 'dept_id']\n","    ids = df_all_data[(df_all_data['store_id']==store_id) & (df_all_data['dept_id']==dept_id)]['id'].drop_duplicates().values\n","    filtered_df = df_all_data[(df_all_data['store_id']==store_id) & (df_all_data['dept_id']==dept_id)].reset_index(drop=True)\n","    filtered_df.reset_index(drop=True, inplace=True)\n","\n","    # Get the number of block items\n","    num_block_items = len(ids)\n","\n","    # Get the number of features\n","    num_features = len(ONCE_ONLY_FEATURES) + len(REPEATED_FEATURES) * num_block_items # Calculate the number of features\n","\n","    # Get the input shape later on for the model\n","    input_shape = (DAYS_PER_SEQUENCE + 1, num_features)\n","\n","    return filtered_df, ids, num_block_items, num_features, input_shape"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:29:02.293651Z","iopub.status.busy":"2024-02-04T10:29:02.293253Z","iopub.status.idle":"2024-02-04T10:29:02.323161Z","shell.execute_reply":"2024-02-04T10:29:02.322166Z","shell.execute_reply.started":"2024-02-04T10:29:02.293598Z"},"trusted":true},"outputs":[],"source":["# create a dataframe that stores only th 5 first items for each day\n","# indices = np.array([np.arange(start, start + num_block_items) for start in range(0, TEST_END * NUM_ITEMS, NUM_ITEMS)]).flatten()\n","# df_all_data = df_all_data.iloc[indices]\n","# df_all_data.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Normalize numerical columns\n","def prepare_df(df_all_data):\n","    # Define categorical and numerical columns\n","    categorical_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'is_available',\n","                        'd', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', \n","                        'snap_CA', 'snap_TX', 'snap_WI']\n","    numerical_cols = ['sell_price']\n","\n","    # Convert categorical columns to category dtype and encode with cat.codes\n","    for col in categorical_cols:\n","        df_all_data[col] = df_all_data[col].astype('category').cat.codes\n","\n","    # Normalize numerical columns\n","    scaler_numerical = MinMaxScaler()\n","    df_all_data[numerical_cols] = scaler_numerical.fit_transform(df_all_data[numerical_cols].astype(np.float32))\n","\n","    scaler_target = MinMaxScaler()\n","    df_all_data[TARGET_COL] = scaler_target.fit_transform(df_all_data[[TARGET_COL]].astype(np.float64))\n","\n","    return df_all_data, scaler_target"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:29:02.326509Z","iopub.status.busy":"2024-02-04T10:29:02.326211Z","iopub.status.idle":"2024-02-04T10:29:02.341825Z","shell.execute_reply":"2024-02-04T10:29:02.340817Z","shell.execute_reply.started":"2024-02-04T10:29:02.326485Z"},"trusted":true},"outputs":[],"source":["def train_test_split(df_all_data):\n","    # For training split up between train and validation dataset, else use all for training and create test dataset\n","    if STATUS=='training':\n","        df_train = df_all_data[df_all_data['d'] < TRAIN_END].reset_index(drop=True)\n","        df_val   = df_all_data[(df_all_data['d'] >= TRAIN_END - DAYS_PER_SEQUENCE) & (df_all_data['d'] < VAL_END)].reset_index(drop=True) #more than 28 days because of the time_steps shift\n","        df_test  = None\n","    elif STATUS=='production':\n","        df_train = df_all_data[df_all_data['d'] < VAL_END].reset_index(drop=True)\n","        df_test  = df_all_data[(df_all_data['d'] >= VAL_END - DAYS_PER_SEQUENCE)   & (df_all_data['d'] < TEST_END)].reset_index(drop=True) #more than 28 days because of the time_steps shift\n","        df_val   = None\n","\n","    # Delete df_all_data to free up memory as data is now stored in df_train, df_val and df_test\n","    del df_all_data\n","\n","    return df_train, df_val, df_test"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["### Create x and y in one go without the generator version autogeneration ###\n","def create_x_y(df, num_block_items):\n","    length_days = len(df) // num_block_items\n","    x = []\n","    y = []\n","    for i in range(0, length_days - DAYS_PER_SEQUENCE):\n","        start_ind = i * num_block_items\n","        end_ind = start_ind + num_block_items * (DAYS_PER_SEQUENCE + 1)  # predict the next day after the sequence\n","\n","        # Extract once-only features for all days in the sequence at once\n","        once_features = df.iloc[start_ind:end_ind:num_block_items][ONCE_ONLY_FEATURES].to_numpy()\n","        # once_features = np.tile(once_features, (NUM_ITEMS, 1, 1)).transpose(1, 0, 2)\n","\n","        # Extract repeated features for all items and days at once\n","        repeated_features_stack = df.iloc[start_ind:end_ind][REPEATED_FEATURES].to_numpy() # 210,000 items, 10 features\n","\n","        # Reshape to a 3D array: 7 days, 30,000 items per day, 10 features\n","        reshaped_3d = repeated_features_stack.reshape(DAYS_PER_SEQUENCE + 1, num_block_items, len(REPEATED_FEATURES))\n","\n","        # Reshape to a 2D array: 7 days, 30,000 items * 10 features each\n","        final_array = reshaped_3d.reshape(DAYS_PER_SEQUENCE + 1, -1)\n","\n","        # Combine once-only and repeated features\n","        batch_sequences = np.concatenate((once_features, final_array), axis=1)\n","\n","        # Reshape batch_sequences to match LSTM input shape\n","        # batch_sequences = batch_sequences.reshape(1, DAYS_PER_SEQUENCE, -1)\n","\n","        # Extract targets\n","        batch_targets = df.iloc[end_ind - num_block_items:end_ind][[TARGET_COL]].to_numpy().flatten()\n","\n","        # Append to x and y\n","        x.append(batch_sequences)\n","        y.append(batch_targets)\n","\n","    return np.array(x), np.array(y)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:29:02.343749Z","iopub.status.busy":"2024-02-04T10:29:02.343338Z","iopub.status.idle":"2024-02-04T10:29:02.353726Z","shell.execute_reply":"2024-02-04T10:29:02.352895Z","shell.execute_reply.started":"2024-02-04T10:29:02.343711Z"},"trusted":true},"outputs":[],"source":["### Use for batch generation input to model ###\n","def lstm_data_generator(df, num_block_items):\n","    length_days = len(df) // num_block_items  # 1941 days\n","    while True:\n","        for i in range(0, length_days - DAYS_PER_SEQUENCE):\n","            start_ind = i * num_block_items\n","            end_ind = start_ind + num_block_items * (DAYS_PER_SEQUENCE + 1)  # predict the next day after the sequence\n","\n","            # Extract once-only features for all days in the sequence at once\n","            once_features = df.iloc[start_ind:end_ind:num_block_items][ONCE_ONLY_FEATURES].to_numpy() # 0,5,10,...295 --> len(once_features)=DAYS_PER_SEQUENCE (60); [3 cols]\n","            # once_features = np.tile(once_features, (NUM_ITEMS, 1, 1)).transpose(1, 0, 2)\n","\n","            # Extract repeated features for all items and days at once\n","            repeated_features_stack = df.iloc[start_ind:end_ind][REPEATED_FEATURES].to_numpy() # 0:300 --> len(repeated_features_stack)=300 ;[3 cols]\n","\n","            # Reshape to a 3D array: 60 days, 5 items ,3 repeated features\n","            reshaped_3d = repeated_features_stack.reshape(DAYS_PER_SEQUENCE, num_block_items, len(REPEATED_FEATURES))\n","\n","            # Reshape to a 2D array: 60 days,  5 items * 3 features each (15)\n","            final_array = reshaped_3d.reshape(DAYS_PER_SEQUENCE, -1)\n","\n","            # Combine once-only and repeated features\n","            batch_sequences = np.concatenate((once_features, final_array), axis=1)\n","\n","            # Reshape batch_sequences to match LSTM input shape\n","            batch_sequences = batch_sequences.reshape(1, DAYS_PER_SEQUENCE, -1)\n","\n","            # Extract targets\n","            batch_targets = df.iloc[end_ind-num_block_items:end_ind][[TARGET_COL]].to_numpy().flatten()\n","\n","            # Yield the batch\n","            yield batch_sequences, batch_targets"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:29:02.355635Z","iopub.status.busy":"2024-02-04T10:29:02.355210Z","iopub.status.idle":"2024-02-04T10:29:02.365871Z","shell.execute_reply":"2024-02-04T10:29:02.364973Z","shell.execute_reply.started":"2024-02-04T10:29:02.355590Z"},"trusted":true},"outputs":[],"source":["# Get the training data and labels array for the LSTM model\n","def get_x_and_y(df_train, df_val, df_test, num_block_items):\n","    # For generator use:\n","    # train_generator = lstm_data_generator(df_train)\n","    # val_generator = lstm_data_generator(df_val)\n","\n","    # For single batch input use:\n","    train_x, train_y = create_x_y(df_train, num_block_items)\n","\n","    if STATUS=='training':\n","        val_x, val_y = create_x_y(df_val, num_block_items)\n","        test_x, test_y = None, None\n","    elif STATUS=='production': \n","        test_x, test_y = create_x_y(df_test, num_block_items)\n","        val_x, val_y = None, None\n","\n","    # df_train not needed anymore\n","    del df_train\n","\n","    return train_x, train_y, val_x, val_y, test_x, test_y"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:29:02.386793Z","iopub.status.busy":"2024-02-04T10:29:02.386108Z","iopub.status.idle":"2024-02-04T10:29:02.392710Z","shell.execute_reply":"2024-02-04T10:29:02.391436Z","shell.execute_reply.started":"2024-02-04T10:29:02.386757Z"},"trusted":true},"outputs":[],"source":["# Custom RMSE loss function\n","def rmse(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true)))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:29:04.259644Z","iopub.status.busy":"2024-02-04T10:29:04.259265Z","iopub.status.idle":"2024-02-04T10:29:04.264825Z","shell.execute_reply":"2024-02-04T10:29:04.263758Z","shell.execute_reply.started":"2024-02-04T10:29:04.259591Z"},"trusted":true},"outputs":[],"source":["class ResetStatesCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        self.model.reset_states()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:29:04.266821Z","iopub.status.busy":"2024-02-04T10:29:04.266222Z","iopub.status.idle":"2024-02-04T10:30:29.341563Z","shell.execute_reply":"2024-02-04T10:30:29.340754Z","shell.execute_reply.started":"2024-02-04T10:29:04.266784Z"},"trusted":true},"outputs":[],"source":["def model_training(model, train_x, train_y, val_x, val_y, epochs):\n","    # Training the model in batches\n","    # history = model.fit(x=train_generator,\n","    #                      steps_per_epoch=TRAIN_DUR,  # total number of sequences in the training set\n","    #                      validation_data=val_generator,\n","    #                      validation_steps=VAL_DUR,  # total number of sequences in the validation set\n","    #                      epochs=epochs,\n","    #                      callbacks=[ResetStatesCallback()])\n","\n","    # Train in one go\n","    if STATUS=='training':\n","        history = model.fit(x=train_x,  # Entire training dataset\n","                        y=train_y,  # Corresponding training labels\n","                        validation_data=(val_x, val_y),  # Entire validation dataset and labels\n","                        epochs=epochs)\n","    elif STATUS=='production':\n","        history = model.fit(x=train_x,  # Entire training dataset\n","                        y=train_y,  # Corresponding training labels\n","                        epochs=epochs)\n","        \n","    return model, history"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def eval(val_x, val_y, model, num_features, scaler_target):\n","    df_eval = pd.DataFrame(columns=['day', 'prediction', 'actual'])\n","    for i in range(0, len(val_x)):\n","        # create new dataframe with the current day, the actual value and the prediction\n","        df_temp = pd.DataFrame({'day': i, 'prediction': model.predict(val_x[i].reshape(1, DAYS_PER_SEQUENCE + 1, num_features), verbose=0).flatten(), 'actual': val_y[i]})\n","        df_eval = pd.concat([df_eval, df_temp], axis=0, ignore_index=True)\n","        # new column with the difference between actual and prediction\n","        df_eval['difference'] = df_eval['actual'] - df_eval['prediction']\n","        # new columns with inverse transformation of actual and prediction\n","        df_eval['actual_inv'] = scaler_target.inverse_transform(df_eval[['actual']]).astype(int)\n","        df_eval['prediction_inv'] = scaler_target.inverse_transform(df_eval[['prediction']]).round(0).astype(int)\n","        # new columns with the difference between actual and prediction\n","        df_eval['difference_inv'] = df_eval['actual_inv'] - df_eval['prediction_inv']\n","    return df_eval"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:52:42.174980Z","iopub.status.busy":"2024-02-04T10:52:42.174264Z","iopub.status.idle":"2024-02-04T10:52:42.181344Z","shell.execute_reply":"2024-02-04T10:52:42.180389Z","shell.execute_reply.started":"2024-02-04T10:52:42.174943Z"},"trusted":true},"outputs":[],"source":["# Evaluation for generator batches\n","def test_eval(val_generator, model, scaler_target):\n","    x, y = next(val_generator)\n","    \n","    prediction_original = model.predict(x)\n","\n","    true_array = scaler_target.inverse_transform(y).flatten()\n","    predicted_array = scaler_target.inverse_transform(prediction_original)[0]\n","    \n","    d = {\"true_array\": true_array, \"predicted_array\": predicted_array}\n","    df = pd.DataFrame(d)\n","    df['predicted_array_rounded'] = df['predicted_array'].round().astype(int)\n","    df['Difference'] = df['true_array'] - df['predicted_array']\n","\n","    print(df)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["################################### Function to forecast the next 28 days (This function for case all data in one batch) ###################################\n","def rolling_forecast(model, df_test, df_val, test_x, test_y, val_x, val_y, scaler_target, num_features, num_block_items):\n","    # Set the df_copy, x_copy and y_copy to the correct dataset\n","    if STATUS=='production':\n","        df_copy = df_test.copy()\n","        x_copy = test_x.copy()\n","        y_copy = test_y.copy()    \n","    \n","    elif STATUS=='training':\n","        df_copy = df_val.copy()\n","        x_copy = val_x.copy()\n","        y_copy = val_y.copy()\n","\n","    # Predict the next 28 days\n","    for i in range(TEST_DUR):\n","        prediction_normalized = model.predict(x_copy[i].reshape(1, DAYS_PER_SEQUENCE + 1, num_features), verbose=0).flatten()\n","    \n","        # Impractical to adjust the prepared array, so we will update the df_test copy and use it to create a new array with the updated prediction values\n","        start_idx = DAYS_PER_SEQUENCE*num_block_items+(i*num_block_items) #df_test starts 14 days earlier because of sliding window --> start at day 14\n","        end_idx = start_idx + num_block_items - 1\n","        df_copy.loc[start_idx:end_idx, TARGET_COL] = prediction_normalized\n","\n","        # Create new df for x and y\n","        x_copy, _ = create_x_y(df_copy, num_block_items)\n","\n","        # Update the y array with the new prediction\n","        y_copy[i] = prediction_normalized\n","    \n","    # Inverse transform the predictions\n","    predictions_original = scaler_target.inverse_transform(y_copy).round(0).astype(int)\n","\n","    # Make sure no negative values are returned\n","    predictions_original[predictions_original < 0] = 0\n","        \n","    return predictions_original\n","#########################################################################################################"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Create a DataFrame for predictions\n","def prepare_fc_to_file(forecast_df, forecast_array, ids):\n","    # Transpose predictions to match the sample submission format\n","    forecast_array = forecast_array.T\n","\n","    # Create array to write to df\n","    forecast_array = np.concatenate((ids.reshape(len(ids),1), forecast_array), axis=1)\n","\n","    # Create a DataFrame for your predictions\n","    forecast_tmp_df = pd.DataFrame(forecast_array, columns=['id'] + [f'F{i+1}' for i in range(28)])\n","\n","    # concatenate forecast to forecast_df\n","    forecast_df = pd.concat([forecast_df, forecast_tmp_df], axis=0, ignore_index=True)\n","\n","    return forecast_df"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def write_to_csv(forecast_df, dir):\n","    # Get validation data\n","    val_df = pd.read_pickle(VALIDATION_DATA)\n","\n","    # Combine forecast with validation data\n","    forecast_df = pd.concat([val_df, forecast_df], axis=0, ignore_index=True)\n","\n","    # Save the forecast to a csv file\n","    forecast_df.to_csv(dir, index=False)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:29:02.401718Z","iopub.status.busy":"2024-02-04T10:29:02.401392Z","iopub.status.idle":"2024-02-04T10:29:02.411354Z","shell.execute_reply":"2024-02-04T10:29:02.410459Z","shell.execute_reply.started":"2024-02-04T10:29:02.401688Z"},"trusted":true},"outputs":[],"source":["# Model parameters\n","epochs = 4\n","batch_size = 1\n","lr = 0.001 #lr = 0.0001\n","clipvalue = 0.5\n","\n","# Model compile parameters\n","loss = rmse\n","optimizer = Adam(learning_rate=lr, clipvalue=clipvalue)\n","metrics = tf.keras.metrics.MeanAbsoluteError()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T10:29:02.412895Z","iopub.status.busy":"2024-02-04T10:29:02.412579Z","iopub.status.idle":"2024-02-04T10:29:04.224334Z","shell.execute_reply":"2024-02-04T10:29:04.223506Z","shell.execute_reply.started":"2024-02-04T10:29:02.412871Z"},"trusted":true},"outputs":[],"source":["# Neu: Architecture to setup when predicting single day steps ahead and not using the repeat vector\n","def create_lstm_model(input_shape, num_block_items):\n","   model = Sequential([\n","      LSTM(units=100, activation='tanh', return_sequences=True, recurrent_dropout=0.1, input_shape=input_shape),\n","      Dropout(0.2),\n","      LSTM(units=60,  activation='tanh', return_sequences=False, recurrent_dropout=0.1),\n","      Dropout(0.2),\n","      Dense(units=num_block_items), # activation='relu', 'softmax; Final Dense layer for output\n","      Reshape((num_block_items,1))]) # Reshape the output to be (number of items)\n","\n","   model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","   # For tracking purposes: check the models parameters\n","   # model.summary()\n","\n","   return model"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# for each store_id and dept_id call get whole data, filter for store_id and dept_id\n","def lstm_pipeline():\n","    df_all_data = get_whole_data()\n","\n","    # Get all store_id and dept_id combinations\n","    df_combinations_store_dep = get_combinations(df_all_data)\n","\n","    # Create empty dataframe to store the forecast\n","    forecast_df = pd.DataFrame(columns=['id'] + [f'F{i+1}' for i in range(28)])\n","\n","    # Loop over all store_id and dept_id combinations, create a model, train it, create the prediction and save it to a file\n","    for i in range(0, len(df_combinations_store_dep)):\n","        print(f'Processing {i+1} of {len(df_combinations_store_dep)}: store_id {df_combinations_store_dep.loc[i, \"store_id\"]} and dept_id {df_combinations_store_dep.loc[i, \"dept_id\"]}')\n","        # Filter df down to only the current store_id and dept_id combination\n","        filtered_df, ids, num_block_items, num_features, input_shape = filter_df(df_combinations_store_dep, df_all_data, i)\n","\n","        print(f\"num items: {num_block_items}\")\n","        # Prepare the data for training\n","        filtered_df, scaler_target = prepare_df(filtered_df)\n","\n","        # Split the data into train, validation and test set\n","        df_train, df_val, df_test = train_test_split(filtered_df)\n","\n","        # Create training, validation and test data arrays from the dataframes\n","        train_x, train_y, val_x, val_y, test_x, test_y = get_x_and_y(df_train, df_val, df_test, num_block_items)\n","\n","        # Create the model\n","        model = create_lstm_model(input_shape, num_block_items)\n","\n","        # Train the model\n","        model_trained, history = model_training(model, train_x, train_y, val_x, val_y, epochs)\n","\n","        # Call eval function to get the evaluation dataframe and some feeling for the results\n","        # df_eval = eval(val_x, val_y, model, num_features, scaler_target)\n","\n","        # Test output for generator\n","        # test_data = test_eval(val_generator, model, scaler_target)\n","\n","        # Create the forecast\n","        predictions_original = rolling_forecast(model_trained, df_test, df_val, test_x, test_y, val_x, val_y, scaler_target, num_features, num_block_items)\n","\n","        forecast_df = prepare_fc_to_file(forecast_df, predictions_original, ids)\n","        print(\"####################################################\\n\")\n","\n","    write_to_csv(forecast_df, sub_dir + 'sample_submission.csv')\n","\n","    return predictions_original"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing 1 of 70: store_id CA_1 and dept_id HOBBIES_1\n","num items: 416\n","Epoch 1/4\n"]},{"name":"stderr","output_type":"stream","text":["2024-02-18 18:33:35.841935: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"]},{"name":"stdout","output_type":"stream","text":["61/61 [==============================] - 3s 29ms/step - loss: 0.0181 - mean_absolute_error: 0.0121\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0093 - mean_absolute_error: 0.0039\n","Epoch 3/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0093 - mean_absolute_error: 0.0039\n","Epoch 4/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0092 - mean_absolute_error: 0.0039\n","####################################################\n","\n","Processing 2 of 70: store_id CA_1 and dept_id HOBBIES_2\n","num items: 149\n","Epoch 1/4\n","61/61 [==============================] - 3s 24ms/step - loss: 0.0221 - mean_absolute_error: 0.0095\n","Epoch 2/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0106 - mean_absolute_error: 0.0048\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0105 - mean_absolute_error: 0.0047\n","Epoch 4/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0105 - mean_absolute_error: 0.0047\n","####################################################\n","\n","Processing 3 of 70: store_id CA_1 and dept_id HOUSEHOLD_1\n","num items: 532\n","Epoch 1/4\n","61/61 [==============================] - 3s 31ms/step - loss: 0.0138 - mean_absolute_error: 0.0073\n","Epoch 2/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0074 - mean_absolute_error: 0.0045\n","Epoch 3/4\n","61/61 [==============================] - 2s 35ms/step - loss: 0.0073 - mean_absolute_error: 0.0044\n","Epoch 4/4\n","61/61 [==============================] - 2s 35ms/step - loss: 0.0070 - mean_absolute_error: 0.0043\n","####################################################\n","\n","Processing 4 of 70: store_id CA_1 and dept_id HOUSEHOLD_2\n","num items: 515\n","Epoch 1/4\n","61/61 [==============================] - 3s 31ms/step - loss: 0.0395 - mean_absolute_error: 0.0154\n","Epoch 2/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0330 - mean_absolute_error: 0.0209\n","Epoch 3/4\n","61/61 [==============================] - 2s 35ms/step - loss: 0.0328 - mean_absolute_error: 0.0206\n","Epoch 4/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0326 - mean_absolute_error: 0.0205\n","####################################################\n","\n","Processing 5 of 70: store_id CA_1 and dept_id FOODS_1\n","num items: 216\n","Epoch 1/4\n","61/61 [==============================] - 3s 24ms/step - loss: 0.0370 - mean_absolute_error: 0.0227\n","Epoch 2/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0261 - mean_absolute_error: 0.0150\n","Epoch 3/4\n","61/61 [==============================] - 2s 27ms/step - loss: 0.0254 - mean_absolute_error: 0.0144\n","Epoch 4/4\n","61/61 [==============================] - 2s 27ms/step - loss: 0.0250 - mean_absolute_error: 0.0141\n","####################################################\n","\n","Processing 6 of 70: store_id CA_1 and dept_id FOODS_2\n","num items: 398\n","Epoch 1/4\n","61/61 [==============================] - 3s 28ms/step - loss: 0.0298 - mean_absolute_error: 0.0165\n","Epoch 2/4\n","61/61 [==============================] - 2s 29ms/step - loss: 0.0220 - mean_absolute_error: 0.0119\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0215 - mean_absolute_error: 0.0117\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0213 - mean_absolute_error: 0.0115\n","####################################################\n","\n","Processing 7 of 70: store_id CA_1 and dept_id FOODS_3\n","num items: 823\n","Epoch 1/4\n","61/61 [==============================] - 4s 32ms/step - loss: 0.0139 - mean_absolute_error: 0.0105\n","Epoch 2/4\n","61/61 [==============================] - 2s 36ms/step - loss: 0.0073 - mean_absolute_error: 0.0035\n","Epoch 3/4\n","61/61 [==============================] - 2s 38ms/step - loss: 0.0072 - mean_absolute_error: 0.0034\n","Epoch 4/4\n","61/61 [==============================] - 2s 37ms/step - loss: 0.0071 - mean_absolute_error: 0.0033\n","####################################################\n","\n","Processing 8 of 70: store_id CA_2 and dept_id HOBBIES_1\n","num items: 416\n","Epoch 1/4\n","61/61 [==============================] - 3s 27ms/step - loss: 0.0289 - mean_absolute_error: 0.0102\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0215 - mean_absolute_error: 0.0094\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0212 - mean_absolute_error: 0.0092\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0211 - mean_absolute_error: 0.0091\n","####################################################\n","\n","Processing 9 of 70: store_id CA_2 and dept_id HOBBIES_2\n","num items: 149\n","Epoch 1/4\n","61/61 [==============================] - 3s 23ms/step - loss: 0.0300 - mean_absolute_error: 0.0139\n","Epoch 2/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0193 - mean_absolute_error: 0.0090\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0193 - mean_absolute_error: 0.0090\n","Epoch 4/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0193 - mean_absolute_error: 0.0090\n","####################################################\n","\n","Processing 10 of 70: store_id CA_2 and dept_id HOUSEHOLD_1\n","num items: 532\n","Epoch 1/4\n","61/61 [==============================] - 4s 32ms/step - loss: 0.0225 - mean_absolute_error: 0.0120\n","Epoch 2/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0161 - mean_absolute_error: 0.0092\n","Epoch 3/4\n","61/61 [==============================] - 2s 35ms/step - loss: 0.0159 - mean_absolute_error: 0.0091\n","Epoch 4/4\n","61/61 [==============================] - 2s 35ms/step - loss: 0.0156 - mean_absolute_error: 0.0088\n","####################################################\n","\n","Processing 11 of 70: store_id CA_2 and dept_id HOUSEHOLD_2\n","num items: 515\n","Epoch 1/4\n","61/61 [==============================] - 3s 29ms/step - loss: 0.0185 - mean_absolute_error: 0.0109\n","Epoch 2/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0117 - mean_absolute_error: 0.0070\n","Epoch 3/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0116 - mean_absolute_error: 0.0070\n","Epoch 4/4\n","61/61 [==============================] - 2s 35ms/step - loss: 0.0116 - mean_absolute_error: 0.0069\n","####################################################\n","\n","Processing 12 of 70: store_id CA_2 and dept_id FOODS_1\n","num items: 216\n","Epoch 1/4\n","61/61 [==============================] - 3s 24ms/step - loss: 0.0296 - mean_absolute_error: 0.0137\n","Epoch 2/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0192 - mean_absolute_error: 0.0109\n","Epoch 3/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0192 - mean_absolute_error: 0.0109\n","Epoch 4/4\n","61/61 [==============================] - 2s 27ms/step - loss: 0.0191 - mean_absolute_error: 0.0108\n","####################################################\n","\n","Processing 13 of 70: store_id CA_2 and dept_id FOODS_2\n","num items: 398\n","Epoch 1/4\n","61/61 [==============================] - 3s 28ms/step - loss: 0.0398 - mean_absolute_error: 0.0161\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0330 - mean_absolute_error: 0.0148\n","Epoch 3/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0325 - mean_absolute_error: 0.0146\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0320 - mean_absolute_error: 0.0144\n","####################################################\n","\n","Processing 14 of 70: store_id CA_2 and dept_id FOODS_3\n","num items: 823\n","Epoch 1/4\n","61/61 [==============================] - 3s 30ms/step - loss: 0.0187 - mean_absolute_error: 0.0131\n","Epoch 2/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0132 - mean_absolute_error: 0.0065\n","Epoch 3/4\n","61/61 [==============================] - 2s 36ms/step - loss: 0.0132 - mean_absolute_error: 0.0065\n","Epoch 4/4\n","61/61 [==============================] - 2s 40ms/step - loss: 0.0131 - mean_absolute_error: 0.0064\n","####################################################\n","\n","Processing 15 of 70: store_id CA_3 and dept_id HOBBIES_1\n","num items: 416\n","Epoch 1/4\n","61/61 [==============================] - 4s 28ms/step - loss: 0.0199 - mean_absolute_error: 0.0097\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0114 - mean_absolute_error: 0.0051\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0112 - mean_absolute_error: 0.0049\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0110 - mean_absolute_error: 0.0047\n","####################################################\n","\n","Processing 16 of 70: store_id CA_3 and dept_id HOBBIES_2\n","num items: 149\n","Epoch 1/4\n","61/61 [==============================] - 3s 23ms/step - loss: 0.0243 - mean_absolute_error: 0.0105\n","Epoch 2/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0137 - mean_absolute_error: 0.0065\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0136 - mean_absolute_error: 0.0065\n","Epoch 4/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0135 - mean_absolute_error: 0.0065\n","####################################################\n","\n","Processing 17 of 70: store_id CA_3 and dept_id HOUSEHOLD_1\n","num items: 532\n","Epoch 1/4\n","61/61 [==============================] - 3s 30ms/step - loss: 0.0349 - mean_absolute_error: 0.0140\n","Epoch 2/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0266 - mean_absolute_error: 0.0144\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0257 - mean_absolute_error: 0.0137\n","Epoch 4/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0254 - mean_absolute_error: 0.0134\n","####################################################\n","\n","Processing 18 of 70: store_id CA_3 and dept_id HOUSEHOLD_2\n","num items: 515\n","Epoch 1/4\n","61/61 [==============================] - 4s 29ms/step - loss: 0.0176 - mean_absolute_error: 0.0132\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0088 - mean_absolute_error: 0.0054\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0087 - mean_absolute_error: 0.0053\n","Epoch 4/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0086 - mean_absolute_error: 0.0053\n","####################################################\n","\n","Processing 19 of 70: store_id CA_3 and dept_id FOODS_1\n","num items: 216\n","Epoch 1/4\n","61/61 [==============================] - 3s 23ms/step - loss: 0.0324 - mean_absolute_error: 0.0134\n","Epoch 2/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0228 - mean_absolute_error: 0.0126\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0226 - mean_absolute_error: 0.0125\n","Epoch 4/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0223 - mean_absolute_error: 0.0123\n","####################################################\n","\n","Processing 20 of 70: store_id CA_3 and dept_id FOODS_2\n","num items: 398\n","Epoch 1/4\n","61/61 [==============================] - 3s 27ms/step - loss: 0.0290 - mean_absolute_error: 0.0152\n","Epoch 2/4\n","61/61 [==============================] - 2s 29ms/step - loss: 0.0214 - mean_absolute_error: 0.0119\n","Epoch 3/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0211 - mean_absolute_error: 0.0117\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0208 - mean_absolute_error: 0.0115\n","####################################################\n","\n","Processing 21 of 70: store_id CA_3 and dept_id FOODS_3\n","num items: 823\n","Epoch 1/4\n","61/61 [==============================] - 4s 34ms/step - loss: 0.0159 - mean_absolute_error: 0.0107\n","Epoch 2/4\n","61/61 [==============================] - 2s 38ms/step - loss: 0.0093 - mean_absolute_error: 0.0036\n","Epoch 3/4\n","61/61 [==============================] - 2s 40ms/step - loss: 0.0091 - mean_absolute_error: 0.0037\n","Epoch 4/4\n","61/61 [==============================] - 2s 40ms/step - loss: 0.0087 - mean_absolute_error: 0.0037\n","####################################################\n","\n","Processing 22 of 70: store_id CA_4 and dept_id HOBBIES_1\n","num items: 416\n","Epoch 1/4\n","61/61 [==============================] - 3s 28ms/step - loss: 0.0197 - mean_absolute_error: 0.0081\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0119 - mean_absolute_error: 0.0050\n","Epoch 3/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0119 - mean_absolute_error: 0.0049\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0118 - mean_absolute_error: 0.0049\n","####################################################\n","\n","Processing 23 of 70: store_id CA_4 and dept_id HOBBIES_2\n","num items: 149\n","Epoch 1/4\n","61/61 [==============================] - 3s 22ms/step - loss: 0.0286 - mean_absolute_error: 0.0113\n","Epoch 2/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0186 - mean_absolute_error: 0.0078\n","Epoch 3/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0184 - mean_absolute_error: 0.0074\n","Epoch 4/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0184 - mean_absolute_error: 0.0073\n","####################################################\n","\n","Processing 24 of 70: store_id CA_4 and dept_id HOUSEHOLD_1\n","num items: 532\n","Epoch 1/4\n","61/61 [==============================] - 3s 30ms/step - loss: 0.0268 - mean_absolute_error: 0.0130\n","Epoch 2/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0200 - mean_absolute_error: 0.0126\n","Epoch 3/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0197 - mean_absolute_error: 0.0123\n","Epoch 4/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0196 - mean_absolute_error: 0.0122\n","####################################################\n","\n","Processing 25 of 70: store_id CA_4 and dept_id HOUSEHOLD_2\n","num items: 515\n","Epoch 1/4\n","61/61 [==============================] - 3s 29ms/step - loss: 0.0122 - mean_absolute_error: 0.0109\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0021 - mean_absolute_error: 0.0012\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0020 - mean_absolute_error: 0.0011\n","Epoch 4/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0020 - mean_absolute_error: 0.0011\n","####################################################\n","\n","Processing 26 of 70: store_id CA_4 and dept_id FOODS_1\n","num items: 216\n","Epoch 1/4\n","61/61 [==============================] - 3s 23ms/step - loss: 0.0409 - mean_absolute_error: 0.0136\n","Epoch 2/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0308 - mean_absolute_error: 0.0170\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0302 - mean_absolute_error: 0.0167\n","Epoch 4/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0299 - mean_absolute_error: 0.0164\n","####################################################\n","\n","Processing 27 of 70: store_id CA_4 and dept_id FOODS_2\n","num items: 398\n","Epoch 1/4\n","61/61 [==============================] - 3s 27ms/step - loss: 0.0412 - mean_absolute_error: 0.0217\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0339 - mean_absolute_error: 0.0204\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0333 - mean_absolute_error: 0.0201\n","Epoch 4/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0332 - mean_absolute_error: 0.0198\n","####################################################\n","\n","Processing 28 of 70: store_id CA_4 and dept_id FOODS_3\n","num items: 823\n","Epoch 1/4\n","61/61 [==============================] - 3s 30ms/step - loss: 0.0200 - mean_absolute_error: 0.0164\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0141 - mean_absolute_error: 0.0075\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0140 - mean_absolute_error: 0.0073\n","Epoch 4/4\n","61/61 [==============================] - 2s 40ms/step - loss: 0.0137 - mean_absolute_error: 0.0072\n","####################################################\n","\n","Processing 29 of 70: store_id TX_1 and dept_id HOBBIES_1\n","num items: 416\n","Epoch 1/4\n","61/61 [==============================] - 4s 28ms/step - loss: 0.0187 - mean_absolute_error: 0.0102\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0086 - mean_absolute_error: 0.0039\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0085 - mean_absolute_error: 0.0037\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0085 - mean_absolute_error: 0.0036\n","####################################################\n","\n","Processing 30 of 70: store_id TX_1 and dept_id HOBBIES_2\n","num items: 149\n","Epoch 1/4\n","61/61 [==============================] - 3s 23ms/step - loss: 0.0245 - mean_absolute_error: 0.0097\n","Epoch 2/4\n","61/61 [==============================] - 1s 24ms/step - loss: 0.0143 - mean_absolute_error: 0.0063\n","Epoch 3/4\n","61/61 [==============================] - 2s 27ms/step - loss: 0.0142 - mean_absolute_error: 0.0062\n","Epoch 4/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0142 - mean_absolute_error: 0.0062\n","####################################################\n","\n","Processing 31 of 70: store_id TX_1 and dept_id HOUSEHOLD_1\n","num items: 532\n","Epoch 1/4\n","61/61 [==============================] - 4s 31ms/step - loss: 0.0163 - mean_absolute_error: 0.0089\n","Epoch 2/4\n","61/61 [==============================] - 2s 37ms/step - loss: 0.0082 - mean_absolute_error: 0.0045\n","Epoch 3/4\n","61/61 [==============================] - 2s 38ms/step - loss: 0.0079 - mean_absolute_error: 0.0043\n","Epoch 4/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0078 - mean_absolute_error: 0.0042\n","####################################################\n","\n","Processing 32 of 70: store_id TX_1 and dept_id HOUSEHOLD_2\n","num items: 515\n","Epoch 1/4\n","61/61 [==============================] - 4s 29ms/step - loss: 0.0108 - mean_absolute_error: 0.0063\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0015 - mean_absolute_error: 8.5302e-04\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0014 - mean_absolute_error: 7.4678e-04\n","Epoch 4/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0014 - mean_absolute_error: 7.1299e-04\n","####################################################\n","\n","Processing 33 of 70: store_id TX_1 and dept_id FOODS_1\n","num items: 216\n","Epoch 1/4\n","61/61 [==============================] - 3s 24ms/step - loss: 0.0285 - mean_absolute_error: 0.0100\n","Epoch 2/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0179 - mean_absolute_error: 0.0095\n","Epoch 3/4\n","61/61 [==============================] - 2s 27ms/step - loss: 0.0178 - mean_absolute_error: 0.0094\n","Epoch 4/4\n","61/61 [==============================] - 2s 27ms/step - loss: 0.0178 - mean_absolute_error: 0.0094\n","####################################################\n","\n","Processing 34 of 70: store_id TX_1 and dept_id FOODS_2\n","num items: 398\n","Epoch 1/4\n","61/61 [==============================] - 3s 30ms/step - loss: 0.0132 - mean_absolute_error: 0.0098\n","Epoch 2/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0028 - mean_absolute_error: 0.0017\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0026 - mean_absolute_error: 0.0015\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0026 - mean_absolute_error: 0.0015\n","####################################################\n","\n","Processing 35 of 70: store_id TX_1 and dept_id FOODS_3\n","num items: 823\n","Epoch 1/4\n","61/61 [==============================] - 4s 32ms/step - loss: 0.0150 - mean_absolute_error: 0.0054\n","Epoch 2/4\n","61/61 [==============================] - 2s 39ms/step - loss: 0.0093 - mean_absolute_error: 0.0039\n","Epoch 3/4\n","61/61 [==============================] - 2s 40ms/step - loss: 0.0092 - mean_absolute_error: 0.0038\n","Epoch 4/4\n","61/61 [==============================] - 2s 40ms/step - loss: 0.0092 - mean_absolute_error: 0.0038\n","####################################################\n","\n","Processing 36 of 70: store_id TX_2 and dept_id HOBBIES_1\n","num items: 416\n","Epoch 1/4\n","61/61 [==============================] - 3s 27ms/step - loss: 0.0230 - mean_absolute_error: 0.0095\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0145 - mean_absolute_error: 0.0071\n","Epoch 3/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0143 - mean_absolute_error: 0.0069\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0142 - mean_absolute_error: 0.0068\n","####################################################\n","\n","Processing 37 of 70: store_id TX_2 and dept_id HOBBIES_2\n","num items: 149\n","Epoch 1/4\n","61/61 [==============================] - 3s 22ms/step - loss: 0.0168 - mean_absolute_error: 0.0092\n","Epoch 2/4\n","61/61 [==============================] - 1s 24ms/step - loss: 0.0073 - mean_absolute_error: 0.0031\n","Epoch 3/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0073 - mean_absolute_error: 0.0031\n","Epoch 4/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0072 - mean_absolute_error: 0.0031\n","####################################################\n","\n","Processing 38 of 70: store_id TX_2 and dept_id HOUSEHOLD_1\n","num items: 532\n","Epoch 1/4\n","61/61 [==============================] - 4s 29ms/step - loss: 0.0137 - mean_absolute_error: 0.0067\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0042 - mean_absolute_error: 0.0021\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0041 - mean_absolute_error: 0.0020\n","Epoch 4/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0040 - mean_absolute_error: 0.0020\n","####################################################\n","\n","Processing 39 of 70: store_id TX_2 and dept_id HOUSEHOLD_2\n","num items: 515\n","Epoch 1/4\n","61/61 [==============================] - 3s 29ms/step - loss: 0.0264 - mean_absolute_error: 0.0101\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0190 - mean_absolute_error: 0.0115\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0189 - mean_absolute_error: 0.0114\n","Epoch 4/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0189 - mean_absolute_error: 0.0114\n","####################################################\n","\n","Processing 40 of 70: store_id TX_2 and dept_id FOODS_1\n","num items: 216\n","Epoch 1/4\n","61/61 [==============================] - 3s 23ms/step - loss: 0.0277 - mean_absolute_error: 0.0150\n","Epoch 2/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0165 - mean_absolute_error: 0.0085\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0156 - mean_absolute_error: 0.0081\n","Epoch 4/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0152 - mean_absolute_error: 0.0078\n","####################################################\n","\n","Processing 41 of 70: store_id TX_2 and dept_id FOODS_2\n","num items: 398\n","Epoch 1/4\n","61/61 [==============================] - 3s 29ms/step - loss: 0.0300 - mean_absolute_error: 0.0135\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0223 - mean_absolute_error: 0.0121\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0221 - mean_absolute_error: 0.0120\n","Epoch 4/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0213 - mean_absolute_error: 0.0118\n","####################################################\n","\n","Processing 42 of 70: store_id TX_2 and dept_id FOODS_3\n","num items: 823\n","Epoch 1/4\n","61/61 [==============================] - 3s 30ms/step - loss: 0.0173 - mean_absolute_error: 0.0112\n","Epoch 2/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0110 - mean_absolute_error: 0.0048\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0109 - mean_absolute_error: 0.0047\n","Epoch 4/4\n","61/61 [==============================] - 2s 36ms/step - loss: 0.0107 - mean_absolute_error: 0.0046\n","####################################################\n","\n","Processing 43 of 70: store_id TX_3 and dept_id HOBBIES_1\n","num items: 416\n","Epoch 1/4\n","61/61 [==============================] - 4s 28ms/step - loss: 0.0195 - mean_absolute_error: 0.0087\n","Epoch 2/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0113 - mean_absolute_error: 0.0051\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0111 - mean_absolute_error: 0.0051\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0107 - mean_absolute_error: 0.0050\n","####################################################\n","\n","Processing 44 of 70: store_id TX_3 and dept_id HOBBIES_2\n","num items: 149\n","Epoch 1/4\n","61/61 [==============================] - 3s 22ms/step - loss: 0.0178 - mean_absolute_error: 0.0087\n","Epoch 2/4\n","61/61 [==============================] - 1s 23ms/step - loss: 0.0082 - mean_absolute_error: 0.0039\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0082 - mean_absolute_error: 0.0038\n","Epoch 4/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0082 - mean_absolute_error: 0.0038\n","####################################################\n","\n","Processing 45 of 70: store_id TX_3 and dept_id HOUSEHOLD_1\n","num items: 532\n","Epoch 1/4\n","61/61 [==============================] - 3s 29ms/step - loss: 0.0239 - mean_absolute_error: 0.0097\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0163 - mean_absolute_error: 0.0090\n","Epoch 3/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0161 - mean_absolute_error: 0.0087\n","Epoch 4/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0159 - mean_absolute_error: 0.0085\n","####################################################\n","\n","Processing 46 of 70: store_id TX_3 and dept_id HOUSEHOLD_2\n","num items: 515\n","Epoch 1/4\n","61/61 [==============================] - 4s 29ms/step - loss: 0.0324 - mean_absolute_error: 0.0149\n","Epoch 2/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0259 - mean_absolute_error: 0.0150\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0257 - mean_absolute_error: 0.0149\n","Epoch 4/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0257 - mean_absolute_error: 0.0148\n","####################################################\n","\n","Processing 47 of 70: store_id TX_3 and dept_id FOODS_1\n","num items: 216\n","Epoch 1/4\n","61/61 [==============================] - 3s 24ms/step - loss: 0.0408 - mean_absolute_error: 0.0200\n","Epoch 2/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0302 - mean_absolute_error: 0.0156\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0293 - mean_absolute_error: 0.0152\n","Epoch 4/4\n","61/61 [==============================] - 2s 27ms/step - loss: 0.0288 - mean_absolute_error: 0.0149\n","####################################################\n","\n","Processing 48 of 70: store_id TX_3 and dept_id FOODS_2\n","num items: 398\n","Epoch 1/4\n","61/61 [==============================] - 3s 27ms/step - loss: 0.0184 - mean_absolute_error: 0.0138\n","Epoch 2/4\n","61/61 [==============================] - 2s 29ms/step - loss: 0.0098 - mean_absolute_error: 0.0050\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0098 - mean_absolute_error: 0.0050\n","Epoch 4/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0098 - mean_absolute_error: 0.0049\n","####################################################\n","\n","Processing 49 of 70: store_id TX_3 and dept_id FOODS_3\n","num items: 823\n","Epoch 1/4\n","61/61 [==============================] - 4s 29ms/step - loss: 0.0172 - mean_absolute_error: 0.0078\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0104 - mean_absolute_error: 0.0043\n","Epoch 3/4\n","61/61 [==============================] - 2s 35ms/step - loss: 0.0103 - mean_absolute_error: 0.0042\n","Epoch 4/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0102 - mean_absolute_error: 0.0042\n","####################################################\n","\n","Processing 50 of 70: store_id WI_1 and dept_id HOBBIES_1\n","num items: 416\n","Epoch 1/4\n","61/61 [==============================] - 3s 28ms/step - loss: 0.0283 - mean_absolute_error: 0.0108\n","Epoch 2/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0199 - mean_absolute_error: 0.0091\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0197 - mean_absolute_error: 0.0090\n","Epoch 4/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0196 - mean_absolute_error: 0.0089\n","####################################################\n","\n","Processing 51 of 70: store_id WI_1 and dept_id HOBBIES_2\n","num items: 149\n","Epoch 1/4\n","61/61 [==============================] - 3s 23ms/step - loss: 0.0313 - mean_absolute_error: 0.0139\n","Epoch 2/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0232 - mean_absolute_error: 0.0109\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0231 - mean_absolute_error: 0.0108\n","Epoch 4/4\n","61/61 [==============================] - 2s 27ms/step - loss: 0.0230 - mean_absolute_error: 0.0109\n","####################################################\n","\n","Processing 52 of 70: store_id WI_1 and dept_id HOUSEHOLD_1\n","num items: 532\n","Epoch 1/4\n","61/61 [==============================] - 4s 30ms/step - loss: 0.0300 - mean_absolute_error: 0.0153\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0237 - mean_absolute_error: 0.0141\n","Epoch 3/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0234 - mean_absolute_error: 0.0138\n","Epoch 4/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0232 - mean_absolute_error: 0.0137\n","####################################################\n","\n","Processing 53 of 70: store_id WI_1 and dept_id HOUSEHOLD_2\n","num items: 515\n","Epoch 1/4\n","61/61 [==============================] - 3s 29ms/step - loss: 0.0244 - mean_absolute_error: 0.0152\n","Epoch 2/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0177 - mean_absolute_error: 0.0105\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0173 - mean_absolute_error: 0.0103\n","Epoch 4/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0172 - mean_absolute_error: 0.0102\n","####################################################\n","\n","Processing 54 of 70: store_id WI_1 and dept_id FOODS_1\n","num items: 216\n","Epoch 1/4\n","61/61 [==============================] - 3s 24ms/step - loss: 0.0235 - mean_absolute_error: 0.0134\n","Epoch 2/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0131 - mean_absolute_error: 0.0074\n","Epoch 3/4\n","61/61 [==============================] - 2s 27ms/step - loss: 0.0129 - mean_absolute_error: 0.0073\n","Epoch 4/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0128 - mean_absolute_error: 0.0072\n","####################################################\n","\n","Processing 55 of 70: store_id WI_1 and dept_id FOODS_2\n","num items: 398\n","Epoch 1/4\n","61/61 [==============================] - 4s 28ms/step - loss: 0.0293 - mean_absolute_error: 0.0133\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0216 - mean_absolute_error: 0.0124\n","Epoch 3/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0214 - mean_absolute_error: 0.0122\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0209 - mean_absolute_error: 0.0117\n","####################################################\n","\n","Processing 56 of 70: store_id WI_1 and dept_id FOODS_3\n","num items: 823\n","Epoch 1/4\n","61/61 [==============================] - 3s 29ms/step - loss: 0.0173 - mean_absolute_error: 0.0117\n","Epoch 2/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0111 - mean_absolute_error: 0.0060\n","Epoch 3/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0109 - mean_absolute_error: 0.0058\n","Epoch 4/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0108 - mean_absolute_error: 0.0057\n","####################################################\n","\n","Processing 57 of 70: store_id WI_2 and dept_id HOBBIES_1\n","num items: 416\n","Epoch 1/4\n","61/61 [==============================] - 3s 28ms/step - loss: 0.0214 - mean_absolute_error: 0.0094\n","Epoch 2/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0141 - mean_absolute_error: 0.0059\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0141 - mean_absolute_error: 0.0058\n","Epoch 4/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0140 - mean_absolute_error: 0.0058\n","####################################################\n","\n","Processing 58 of 70: store_id WI_2 and dept_id HOBBIES_2\n","num items: 149\n","Epoch 1/4\n","61/61 [==============================] - 3s 23ms/step - loss: 0.0217 - mean_absolute_error: 0.0103\n","Epoch 2/4\n","61/61 [==============================] - 1s 24ms/step - loss: 0.0102 - mean_absolute_error: 0.0044\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0102 - mean_absolute_error: 0.0043\n","Epoch 4/4\n","61/61 [==============================] - 2s 27ms/step - loss: 0.0102 - mean_absolute_error: 0.0043\n","####################################################\n","\n","Processing 59 of 70: store_id WI_2 and dept_id HOUSEHOLD_1\n","num items: 532\n","Epoch 1/4\n","61/61 [==============================] - 3s 30ms/step - loss: 0.0308 - mean_absolute_error: 0.0116\n","Epoch 2/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0231 - mean_absolute_error: 0.0119\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0225 - mean_absolute_error: 0.0114\n","Epoch 4/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0222 - mean_absolute_error: 0.0112\n","####################################################\n","\n","Processing 60 of 70: store_id WI_2 and dept_id HOUSEHOLD_2\n","num items: 515\n","Epoch 1/4\n","61/61 [==============================] - 3s 29ms/step - loss: 0.0237 - mean_absolute_error: 0.0131\n","Epoch 2/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0179 - mean_absolute_error: 0.0094\n","Epoch 3/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0178 - mean_absolute_error: 0.0093\n","Epoch 4/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0175 - mean_absolute_error: 0.0093\n","####################################################\n","\n","Processing 61 of 70: store_id WI_2 and dept_id FOODS_1\n","num items: 216\n","Epoch 1/4\n","61/61 [==============================] - 3s 25ms/step - loss: 0.0391 - mean_absolute_error: 0.0164\n","Epoch 2/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0286 - mean_absolute_error: 0.0140\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0276 - mean_absolute_error: 0.0136\n","Epoch 4/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0271 - mean_absolute_error: 0.0132\n","####################################################\n","\n","Processing 62 of 70: store_id WI_2 and dept_id FOODS_2\n","num items: 398\n","Epoch 1/4\n","61/61 [==============================] - 3s 29ms/step - loss: 0.0195 - mean_absolute_error: 0.0132\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0112 - mean_absolute_error: 0.0056\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0108 - mean_absolute_error: 0.0053\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0105 - mean_absolute_error: 0.0052\n","####################################################\n","\n","Processing 63 of 70: store_id WI_2 and dept_id FOODS_3\n","num items: 823\n","Epoch 1/4\n","61/61 [==============================] - 4s 30ms/step - loss: 0.0246 - mean_absolute_error: 0.0095\n","Epoch 2/4\n","61/61 [==============================] - 2s 38ms/step - loss: 0.0187 - mean_absolute_error: 0.0079\n","Epoch 3/4\n","61/61 [==============================] - 2s 39ms/step - loss: 0.0183 - mean_absolute_error: 0.0077\n","Epoch 4/4\n","61/61 [==============================] - 2s 40ms/step - loss: 0.0182 - mean_absolute_error: 0.0075\n","####################################################\n","\n","Processing 64 of 70: store_id WI_3 and dept_id HOBBIES_1\n","num items: 416\n","Epoch 1/4\n","61/61 [==============================] - 3s 27ms/step - loss: 0.0162 - mean_absolute_error: 0.0097\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0061 - mean_absolute_error: 0.0030\n","Epoch 3/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0060 - mean_absolute_error: 0.0028\n","Epoch 4/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0059 - mean_absolute_error: 0.0027\n","####################################################\n","\n","Processing 65 of 70: store_id WI_3 and dept_id HOBBIES_2\n","num items: 149\n","Epoch 1/4\n","61/61 [==============================] - 3s 22ms/step - loss: 0.0232 - mean_absolute_error: 0.0097\n","Epoch 2/4\n","61/61 [==============================] - 1s 24ms/step - loss: 0.0102 - mean_absolute_error: 0.0049\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0099 - mean_absolute_error: 0.0044\n","Epoch 4/4\n","61/61 [==============================] - 2s 25ms/step - loss: 0.0098 - mean_absolute_error: 0.0042\n","####################################################\n","\n","Processing 66 of 70: store_id WI_3 and dept_id HOUSEHOLD_1\n","num items: 532\n","Epoch 1/4\n","61/61 [==============================] - 4s 30ms/step - loss: 0.0341 - mean_absolute_error: 0.0126\n","Epoch 2/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0275 - mean_absolute_error: 0.0149\n","Epoch 3/4\n","61/61 [==============================] - 2s 35ms/step - loss: 0.0262 - mean_absolute_error: 0.0141\n","Epoch 4/4\n","61/61 [==============================] - 2s 34ms/step - loss: 0.0259 - mean_absolute_error: 0.0140\n","####################################################\n","\n","Processing 67 of 70: store_id WI_3 and dept_id HOUSEHOLD_2\n","num items: 515\n","Epoch 1/4\n","61/61 [==============================] - 3s 29ms/step - loss: 0.0212 - mean_absolute_error: 0.0144\n","Epoch 2/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0131 - mean_absolute_error: 0.0075\n","Epoch 3/4\n","61/61 [==============================] - 2s 33ms/step - loss: 0.0128 - mean_absolute_error: 0.0073\n","Epoch 4/4\n","61/61 [==============================] - 2s 32ms/step - loss: 0.0127 - mean_absolute_error: 0.0072\n","####################################################\n","\n","Processing 68 of 70: store_id WI_3 and dept_id FOODS_1\n","num items: 216\n","Epoch 1/4\n","61/61 [==============================] - 3s 23ms/step - loss: 0.0265 - mean_absolute_error: 0.0122\n","Epoch 2/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0166 - mean_absolute_error: 0.0081\n","Epoch 3/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0166 - mean_absolute_error: 0.0080\n","Epoch 4/4\n","61/61 [==============================] - 2s 26ms/step - loss: 0.0166 - mean_absolute_error: 0.0080\n","####################################################\n","\n","Processing 69 of 70: store_id WI_3 and dept_id FOODS_2\n","num items: 398\n","Epoch 1/4\n","61/61 [==============================] - 4s 29ms/step - loss: 0.0343 - mean_absolute_error: 0.0147\n","Epoch 2/4\n","61/61 [==============================] - 2s 30ms/step - loss: 0.0248 - mean_absolute_error: 0.0134\n","Epoch 3/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0239 - mean_absolute_error: 0.0129\n","Epoch 4/4\n","61/61 [==============================] - 2s 31ms/step - loss: 0.0234 - mean_absolute_error: 0.0127\n","####################################################\n","\n","Processing 70 of 70: store_id WI_3 and dept_id FOODS_3\n","num items: 823\n","Epoch 1/4\n","61/61 [==============================] - 3s 30ms/step - loss: 0.0191 - mean_absolute_error: 0.0121\n","Epoch 2/4\n","61/61 [==============================] - 2s 37ms/step - loss: 0.0129 - mean_absolute_error: 0.0055\n","Epoch 3/4\n","61/61 [==============================] - 2s 39ms/step - loss: 0.0127 - mean_absolute_error: 0.0053\n","Epoch 4/4\n","61/61 [==============================] - 2s 38ms/step - loss: 0.0124 - mean_absolute_error: 0.0052\n","####################################################\n","\n"]}],"source":["forecast_df = lstm_pipeline()"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1, 4, 0, ..., 1, 1, 0],\n","       [1, 4, 0, ..., 1, 1, 0],\n","       [1, 4, 0, ..., 1, 1, 1],\n","       ...,\n","       [1, 4, 0, ..., 1, 1, 0],\n","       [1, 4, 0, ..., 1, 1, 0],\n","       [1, 4, 0, ..., 1, 1, 0]])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["forecast_df"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'iloc'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test output\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# forecast_df.head(30)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# every 5h row\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m forecast_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m4\u001b[39m::\u001b[38;5;241m416\u001b[39m,]\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"]}],"source":["# Test output\n","# forecast_df.head(30)\n","# every 5h row\n","forecast_df.iloc[4::416,]\n","#how many rows with day = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # For testing purposes: check how large on batch is\n","# # next train_generator\n","# x, y = next(train_generator)\n","\n","# # size of memory in mb of x and y\n","# # print(train_x.nbytes / 1e6)\n","# # print(train_y.nbytes / 1e6)\n","\n","# print(train_x.shape)\n","# print(train_y.shape)\n","# print(x.shape)\n","# print(y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # Save the model to a specified directory\n","# if CODE_ENV=='local':\n","#     ###local###\n","#     model.save(src_dir + 'models/' + MODEL_NAME + '.h5')\n","    \n","# if CODE_ENV=='kaggle':\n","#     ###On Kaggle###\n","#     model.save('/kaggle/working/' + MODEL_NAME + '.h5')\n","\n","# if CODE_ENV=='aws':\n","#     ###aws###\n","#     model.save(src_dir + 'models/' + MODEL_NAME + '.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Start from here if you want to load the model\n","# from keras.models import load_model\n","\n","# # Load the model from a specified directory\n","# if CODE_ENV=='local':\n","#     ###local###\n","#     model = load_model(src_dir + 'models/' + MODEL_NAME + '.h5', custom_objects={'rmse': rmse})\n","\n","# if CODE_ENV=='kaggle':\n","#     ###On Kaggle###\n","#     model = load_model('/kaggle/input/v1-model/' + MODEL_NAME + '.h5', custom_objects={'rmse': rmse})\n","\n","# if CODE_ENV=='aws':\n","#     ###aws###\n","#     model.save(src_dir + 'models/' + MODEL_NAME + '.h5', custom_objects={'rmse': rmse})"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","try:\n","    # Plot training & validation loss values\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.show()\n","except:\n","    print('No history to plot')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def prepare_forecast_input(df, DAYS_PER_SEQUENCE, num_items):\n","#     #df_test starts at 1942-7 which we need take into account\n","#     # Prepare input data for forecasting\n","#     forecast_input = []\n","#     for target_day in range(28):\n","#         start_idx = target_day * num_items\n","#         end_idx = start_idx + DAYS_PER_SEQUENCE * num_items\n","#         sequence = df.iloc[start_idx:end_idx].drop('sales_amount', axis=1).to_numpy()\n","#         forecast_input.append(sequence)\n","#     return np.array(forecast_input)\n","\n","\n","# Custom function for input to prepare forecasts input for model\n","# def prepare_forecast_input(df, target, model, DAYS_PER_SEQUENCE, num_items):\n","#     forecast_output = []\n","#     for target_day in range(28):\n","#         start_idx = target_day * num_items\n","#         end_idx = start_idx + DAYS_PER_SEQUENCE * num_items\n","#         sequence = df.iloc[start_idx:end_idx, : ].drop(target, axis=1).to_numpy()\n","#         # forecast_output.append(model.predict(sequence))\n","#         forecast_output.append(model.predict(sequence.reshape(1, sequence.shape[0], sequence.shape[1])))\n","#     return np.array(forecast_output)#.reshape(-1, 1)\n","# forecast_output = prepare_forecast_input(df_test, TARGET_COL, model, DAYS_PER_SEQUENCE, NUM_ITEMS)\n","#forecasts_original = scaler.inverse_transform(forecast_output)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Assuming df_all_data contains all data up to day 1941\n","# forecast_input = prepare_forecast_input(df_test, DAYS_PER_SEQUENCE, NUM_ITEMS)\n","\n","# Generate forecasts\n","# forecasts = model.predict(forecast_input)\n","# forecasts_original = scaler.inverse_transform(forecasts)\n","\n","# forecasts_original now contains the predicted sales amounts for days 1942 to 1969\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Prepare input for forecasts\n","# I cannot use the custom lstm_data_generator\n","# Prepare 7 day slices each shifted by one day\n","def prepare_forecast_input(df, DAYS_PER_SEQUENCE, target_col):\n","    forecast_input = []\n","    for i in range(0, len(df)//NUM_ITEMS): #i=0; 1, 2, 3, ..., 35?\n","        if i + DAYS_PER_SEQUENCE < (len(df)-1)//NUM_ITEMS: #7, 8, 9, 10, ...\n","            start_idx = i*NUM_ITEMS\n","            end_idx   = start_idx + NUM_ITEMS * DAYS_PER_SEQUENCE\n","            sequence  = df.iloc[start_idx : end_idx, :].drop(target_col, axis=1).to_numpy()\n","            forecast_input.append(sequence)\n","    return np.array(forecast_input)\n","\n","# predict_array = prepare_forecast_input(df=df_test, DAYS_PER_SEQUENCE=DAYS_PER_SEQUENCE, target_col=TARGET_COL)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Now, let's define a function to calculate WRMSSE by calculating the RMSSE for each series and then multiplying by the weights and summing them up. \n","def calculate_weights(sales_data, last_n_days=28):\n","    # sales_data: DataFrame with columns ['item_id', 'day', 'sales']\n","    # Sum sales for each item over the last_n_days\n","    item_sales = sales_data[sales_data['day'] > sales_data['day'].max() - last_n_days].groupby('item_id')['sales'].sum()\n","    # Total sales for all items\n","    total_sales = item_sales.sum()\n","    # Calculate weights\n","    weights = item_sales / total_sales\n","    return weights\n","\n","def rmsse(y_true, y_pred, h, y_train):\n","    numerator = np.sum((y_true - y_pred) ** 2) / h\n","    denominator = np.sum(np.diff(y_train) ** 2) / (len(y_train) - 1) # np.diff to calc the diff for consecutive elements\n","    return np.sqrt(numerator / denominator)\n","\n","def wrmsse(y_trues, y_preds, weights, h, y_trains):\n","    rmsse_values = [rmsse(y_true, y_pred, h, y_train) for y_true, y_pred, y_train in zip(y_trues, y_preds, y_trains)]\n","    return np.sum(np.array(weights) * np.array(rmsse_values))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Evaluate the model on the test set\n","def evaluate_model_wrmsse(model, df_test, df_train, df_val, batch_size, DAYS_PER_SEQUENCE, n):\n","    test_gen = lstm_data_generator(df_test, target_col, DAYS_PER_SEQUENCE, batch_size)\n","    steps = max(1, len(df_test) // (batch_size * n))  # Ensure at least 1 step\n","    y_pred_normalized = model.predict(test_gen, steps=steps)\n","    y_pred_original = scaler.inverse_transform(y_pred_normalized)\n","    y_true_normalized = df_test[target_col].values\n","    y_true_original = scaler.inverse_transform(y_true_normalized)\n","    \n","    #First concatenate all elements used for training (df_train and df_val)\n","    y_train_all_normalized = pd.concat([df_train[target_col], df_val[target_col]], axis=0).values\n","    y_train_all_original = scaler.inverse_transform(y_train_all_normalized)\n","    \n","    # Reshape the predictions and actuals to separate each item's time series\n","    y_pred_series = [y_pred_original[i::NUM_ITEMS] for i in range(NUM_ITEMS)]\n","    y_true_series = [y_true_original[i::NUM_ITEMS] for i in range(NUM_ITEMS)]\n","\n","    # Similarly reshape the training data for RMSSE calculation\n","    y_train_all_series = [y_train_all_original[i::NUM_ITEMS] for i in range(NUM_ITEMS)]\n","\n","    # Check - can be deleted later on\n","    print('len y_pred_series: ' + len(y_pred_series))\n","    print('len y_true_series: ' + len(y_true_series))\n","    print('len y_train_all_series: ' + len(y_train_all_series))\n","    \n","    # Calculate WRMSSE\n","    weights = calculate_weights(sales_data)\n","    wrmsse_score = wrmsse(y_trues=y_true_series, y_preds=y_pred_series, weights=weights, h=28, y_trains=y_train_all_series)\n","\n","    print(\"Test WRMSSE: \", wrmsse_score)\n","    \n","    \n","    \n","    \n","    \n","    \n","    \n","    \n","    \n","    # Calculate wrmsse score\n","    wrmsse_score = wrmsse(\n","        y_trues=y_true_original,\n","        y_preds=y_pred_original,\n","        weights=calculate_weights(sales_data),\n","        h=28, # forecast horizon\n","        y_train=y_train_all_original\n","    )\n","    print(\"Test WRMSSE: \", wrmsse_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Call the evaluate function\n","# evaluate_model_wrmsse(model, df_test, df_train, df_val, batch_size, DAYS_PER_SEQUENCE, VAL_END)"]},{"cell_type":"markdown","metadata":{},"source":["- Cross validation\n","- lambda irgendwo nutzen\n","- TPU nutzen und direkt aufrufen\n","- mutiprocessing\n","- use tensorflow dataset\n","- gpu nutzen (CUDA aufrufen)\n","- ConvLSTM1D layer: https://keras.io/api/layers/recurrent_layers/conv_lstm1d/\n","- https://www.kaggle.com/code/li325040229/eda-and-an-encoder-decoder-lstm-with-9-features/notebook#Build-a-LSTM-Model-\n","- Wie zum laufen bekommen?:\n","-   <b>Encoder-Decoder Model</b> --> https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/144243\n","-   https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/144243 --> 30490 als batch input nutzen, dann aber Problem, dass scheinbar nur Abhängigkeiten von einem auf den anderen Tag getrackt werden und keine Muster zwischen Zeitsequenzen gefunden werden können\n","- Herangehensweise:\n","    - Develop one model per site.\n","    -  Develop one model per group of sites.\n","    -  Develop one model for all sites.\n","\n","\n","<br>\n","\n","- Progress bars mit tqdm anzeigen\n","- Test, Validierung und Trainingzeitraum sollten sich nicht überlappen, ist aber ggf. der Fall?\n","- Ggf. zu float16 konvertieren checken, ob finaler df mit time slices dann deutlich kleiner und performance testen\n","- column 'd' in training df löschen?\n","- paralletl computing einstellen\n","- use_multiprocessing in keras auf true setzen (model.fit agument)\n","- Cross validation?\n","- Ensemble learning?\n","- brauche ich one-hot encoding für categorical features?\n","- Things to consider:\n","- dropout\n","- seed\n","- learning rate\n","- loss function\n","- optimizer\n","- metrics\n","- batch size\n","- epochs\n","- Add CNN layer\n","- model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(DAYS_PER_SEQUENCE, num_features)))\n","- model.add(MaxPooling1D(pool_size=2))\n","- model.add(Flatten())\n","- model.add(LSTM(50, activation='relu'))\n","- model.add(Dense(1)) / or more layers as needed\n","- model.compile()"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":1236839,"sourceId":18599,"sourceType":"competition"},{"datasetId":4320670,"sourceId":7425680,"sourceType":"datasetVersion"},{"datasetId":4322354,"sourceId":7427996,"sourceType":"datasetVersion"},{"datasetId":4322850,"sourceId":7428689,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
